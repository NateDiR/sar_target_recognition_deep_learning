{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import * \n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "params = {\"ytick.color\" : \"w\",\n",
    "          \"xtick.color\" : \"w\",\n",
    "          \"axes.labelcolor\" : \"w\",\n",
    "          \"axes.edgecolor\" : \"w\",\n",
    "          \"figure.figsize\" : (10,10),\n",
    "          \"axes.titlecolor\" : 'w'}\n",
    "\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (128,128)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = image_dataset_from_directory('mstar_imgs',\n",
    "                                           subset='training',\n",
    "                                           image_size=image_size,\n",
    "                                           labels='inferred',\n",
    "                                           validation_split=.2,\n",
    "                                           seed=10,\n",
    "                                           label_mode='categorical',\n",
    "                                           color_mode='grayscale',\n",
    "                                           batch_size=batch_size)\n",
    "\n",
    "val_ds = image_dataset_from_directory('mstar_imgs',\n",
    "                                           subset='validation',\n",
    "                                           image_size=image_size,\n",
    "                                           labels='inferred',\n",
    "                                           validation_split=.2,\n",
    "                                           seed=10,\n",
    "                                           label_mode='categorical',\n",
    "                                           color_mode='grayscale',\n",
    "                                           batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "with plt.rc_context(params):\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "      ax = plt.subplot(3, 3, i + 1)\n",
    "      plt.imshow(images[i].numpy().astype(\"uint8\"), cmap='gray')\n",
    "      plt.title(class_names[np.argmax(labels[i])], )\n",
    "      plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_batches = tf.data.experimental.cardinality(val_ds)\n",
    "test_ds = val_ds.take(val_batches // 5)\n",
    "val_ds = val_ds.skip(val_batches // 5)\n",
    "\n",
    "print('Number of validation batches: %d' % tf.data.experimental.cardinality(val_ds))\n",
    "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=9\n",
    "\n",
    "metrics = [\n",
    "      keras.metrics.CategoricalAccuracy(name='categorical_accuracy'),\n",
    "      tfa.metrics.MatthewsCorrelationCoefficient(num_classes=9, name='MCC'),\n",
    "      tfa.metrics.FBetaScore(num_classes=9, average='weighted', beta=2.0, name='F2'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = keras.Sequential()\n",
    "\n",
    "model1.add(InputLayer(input_shape=(image_size + (1,))))\n",
    "\n",
    "model1.add(Flatten())\n",
    "\n",
    "model1.add(Dense(100, activation='relu'))\n",
    "model1.add(Dense(100, activation='relu'))\n",
    "model1.add(Dense(100, activation='relu'))\n",
    "\n",
    "model1.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = model1.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def holdout_results(model):\n",
    "    result = model.evaluate(test_ds)\n",
    "    return dict(zip(model.metrics_names, result))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "  with plt.rc_context(params):    \n",
    "    metrics = ['loss', 'prc', 'F2', 'MCC']\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for n, metric in enumerate(metrics):\n",
    "      name = metric.replace(\"_\",\" \").capitalize()\n",
    "      plt.subplot(2,2,n+1)\n",
    "      plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "      plt.plot(history.epoch, history.history['val_'+metric],\n",
    "              color=colors[0], linestyle=\"--\", label='Val')\n",
    "      plt.xlabel('Epoch')\n",
    "      plt.ylabel(name)\n",
    "      if metric == 'loss':\n",
    "        plt.ylim([0, plt.ylim()[1]])\n",
    "      elif metric == 'auc':\n",
    "        plt.ylim([0.8,1])\n",
    "      elif metric == 'MCC':\n",
    "        plt.ylim([-1,1])\n",
    "      else:\n",
    "        plt.ylim([0,1])\n",
    "\n",
    "      plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(model, data):\n",
    "    with plt.rc_context(params):\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for x,y in data:\n",
    "            y= tf.argmax(y,axis=1)\n",
    "            y_true.append(y)\n",
    "            y_pred.append(tf.argmax(model.predict(x),axis = 1))\n",
    "    \n",
    "        y_pred = tf.concat(y_pred, axis=0)\n",
    "        y_true = tf.concat(y_true, axis=0)\n",
    "\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        fig = plt.figure(figsize = (10,10))\n",
    "        ax1 = fig.add_subplot(1,1,1)\n",
    "        sns.set(font_scale=1.4) #for label size\n",
    "        sns.heatmap(cm,cmap='binary', annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, annot_kws={\"size\": 10},\n",
    "            cbar = False);\n",
    "        ax1.set_ylabel('True Values',fontsize=14)\n",
    "        ax1.set_xlabel('Predicted Values',fontsize=14)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = keras.utils.load_img(\n",
    "    path=\"C:\\\\Users\\\\nated\\\\Documents\\\\GitHub\\\\sar_target_recognition_deep_learning\\\\holdout_imgs\\\\t72_kuwait.jpg\",\n",
    "    color_mode='grayscale',\n",
    "    target_size=(128,128)\n",
    ")\n",
    "\n",
    "image_array = keras.utils.img_to_array(image)\n",
    "image_array = tf.expand_dims(image_array, 0)\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_t72(model):\n",
    "    predictions = model.predict(image_array)\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "    return(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(model1, val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_results(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(model1, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_t72(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(image_size + (1,))),\n",
    "  tf.keras.layers.Rescaling(1./255),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model2.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(model2, val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_results(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(model2, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN = Sequential()\n",
    "CNN.add(InputLayer(input_shape=(image_size + (1,))))\n",
    "CNN.add(Conv2D(filters=10, kernel_size=3, activation='relu', padding='same'))\n",
    "CNN.add(MaxPooling2D())\n",
    "CNN.add(Conv2D(filters=20, kernel_size=3, activation='relu', padding='same'))\n",
    "CNN.add(MaxPooling2D())\n",
    "CNN.add(Conv2D(filters=30, kernel_size=3, activation='relu', padding='same'))\n",
    "CNN.add(GlobalAveragePooling2D())\n",
    "CNN.add(Dense(20, activation='relu'))\n",
    "CNN.add(Dense(num_classes, activation='softmax'))\n",
    "CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_hist = CNN.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(cnn_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(CNN, val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_results(CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(CNN, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_and_rescale = tf.keras.Sequential([\n",
    "  keras.layers.Resizing(128,128),\n",
    "  keras.layers.Rescaling(1./255)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        keras.layers.RandomRotation(0.2),\n",
    "        keras.layers.RandomZoom(0.1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        augmented_images = data_augmentation(images)\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"), cmap='gray')\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    # Image augmentation block\n",
    "    x = resize_and_rescale(inputs)\n",
    "    x = data_augmentation(x)\n",
    "\n",
    "    # Entry block\n",
    "    x = keras.layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(64, 3, padding=\"same\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [128, 256, 512, 728]:\n",
    "        x = keras.layers.Activation(\"relu\")(x)\n",
    "        x = keras.layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = keras.layers.Activation(\"relu\")(x)\n",
    "        x = keras.layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = keras.layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = keras.layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = keras.layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = keras.layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "\n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "    outputs = keras.layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "xception = make_model(input_shape=image_size + (1,), num_classes=9)\n",
    "xception.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=[\n",
    "        keras.callbacks.EarlyStopping(patience=10, verbose=1, monitor='val_F2', mode='max', restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(factor=.5, patience=3, verbose=1),\n",
    "    ]\n",
    "xception.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=metrics,\n",
    ")\n",
    "xception_hist = xception.fit(\n",
    "    train_ds, epochs=100, callbacks=callbacks, validation_data=val_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(xception_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(xception, val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_results(xception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(xception,test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = image_dataset_from_directory('mstar_imgs',\n",
    "                                           subset='training',\n",
    "                                           image_size=image_size,\n",
    "                                           labels='inferred',\n",
    "                                           validation_split=.2,\n",
    "                                           seed=10,\n",
    "                                           label_mode='categorical',\n",
    "                                           color_mode='rgb',\n",
    "                                           batch_size=batch_size)\n",
    "\n",
    "val_ds = image_dataset_from_directory('mstar_imgs',\n",
    "                                           subset='validation',\n",
    "                                           image_size=image_size,\n",
    "                                           labels='inferred',\n",
    "                                           validation_split=.2,\n",
    "                                           seed=10,\n",
    "                                           label_mode='categorical',\n",
    "                                           color_mode='rgb',\n",
    "                                           batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_batches = tf.data.experimental.cardinality(val_ds)\n",
    "test_ds = val_ds.take(val_batches // 5)\n",
    "val_ds = val_ds.skip(val_batches // 5)\n",
    "\n",
    "print('Number of validation batches: %d' % tf.data.experimental.cardinality(val_ds))\n",
    "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_base = VGG19(include_top=False, weights= 'imagenet', input_shape=(128, 128, 3))\n",
    "vgg_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = keras.models.Sequential()\n",
    "vgg_model.add(Input(shape=image_size + (3,)))\n",
    "vgg_model.add(Rescaling(1./255))\n",
    "vgg_model.add(RandomFlip('horizontal_and_vertical'))\n",
    "vgg_model.add(RandomRotation(0.2))\n",
    "vgg_model.add(RandomZoom(0.1))\n",
    "vgg_model.add(vgg_base)\n",
    "vgg_model.add(Flatten())\n",
    "vgg_model.add(Dense(1024, activation='relu'))\n",
    "vgg_model.add(Dropout(0.5))\n",
    "vgg_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=metrics,)\n",
    "\n",
    "vgg_hist = vgg_model.fit(\n",
    "    train_ds, epochs=100, callbacks=callbacks, validation_data=val_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(vgg_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(vgg_model, val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_results(vgg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(vgg_model,test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(image_size + (3,))),\n",
    "  tf.keras.layers.Rescaling(1./255),\n",
    "  tf.keras.layers.RandomFlip('horizontal_and_vertical'),\n",
    "  tf.keras.layers.RandomRotation(0.2),\n",
    "  tf.keras.layers.RandomZoom(0.1),\n",
    "  tf.keras.layers.Conv2D(128, 5, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(64, 4, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(16, 2, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(1024, activation='relu'),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "last_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=metrics,)\n",
    "\n",
    "last_model_hist = last_model.fit(\n",
    "    train_ds, epochs=100, callbacks=callbacks, validation_data=val_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(last_model_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(last_model, val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_results(last_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = keras.utils.load_img(\n",
    "    path=\"C:\\\\Users\\\\nated\\\\Documents\\\\GitHub\\\\sar_target_recognition_deep_learning\\\\holdout_imgs\\\\t72_kuwait.jpg\",\n",
    "    color_mode='rgb',\n",
    "    target_size=(128,128)\n",
    ")\n",
    "\n",
    "image\n",
    "\n",
    "image_array = keras.utils.img_to_array(image)\n",
    "image_array = tf.expand_dims(image_array, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_t72(last_model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ba974a532f120e0df76c18c06cc7bc66a8d2da08e4a542a44de50e0193cefea"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('metis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
